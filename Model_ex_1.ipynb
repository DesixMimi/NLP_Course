{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e28ccb-f382-4bf4-90fa-e4cb5afc10e8",
   "metadata": {
    "id": "07e28ccb-f382-4bf4-90fa-e4cb5afc10e8"
   },
   "source": [
    "## Models experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1b1d28-a49e-4ce0-9132-bb8b3144824b",
   "metadata": {
    "id": "6e1b1d28-a49e-4ce0-9132-bb8b3144824b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desislavamarvakov/opt/anaconda3/envs/Study/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from transformers import (\n",
    "    AutoModel, AutoConfig, AutoTokenizer,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer, TrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "869e7643-7bac-418b-9556-cfeaa9e720af",
   "metadata": {
    "id": "869e7643-7bac-418b-9556-cfeaa9e720af",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('preprocessed_text_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd8d3ed-dfa1-4016-9500-47de69fd0234",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cd8d3ed-dfa1-4016-9500-47de69fd0234",
    "outputId": "9ce96850-0cc7-448c-92d1-600f1c44c413",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3006566 entries, 0 to 3006565\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   author                    object \n",
      " 1   body                      object \n",
      " 2   word_count                float64\n",
      " 3   word_count_quoteless      float64\n",
      " 4   lang                      object \n",
      " 5   N_exaggeration_count      int64  \n",
      " 6   A_hedges                  float64\n",
      " 7   agreeableness             float64\n",
      " 8   openness                  float64\n",
      " 9   conscientiousness         float64\n",
      " 10  extraversion              float64\n",
      " 11  neuroticism               float64\n",
      " 12  agreeableness_scaled      int64  \n",
      " 13  openness_scaled           int64  \n",
      " 14  conscientiousness_scaled  int64  \n",
      " 15  extraversion_scaled       int64  \n",
      " 16  neuroticism_scaled        int64  \n",
      " 17  clean_text                object \n",
      "dtypes: float64(8), int64(6), object(4)\n",
      "memory usage: 412.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa0da87-f6da-4922-b79c-402e38dcae72",
   "metadata": {
    "id": "faa0da87-f6da-4922-b79c-402e38dcae72",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert columns to the correct data types\n",
    "data[\"author\"] = data[\"author\"].astype(str)\n",
    "data[\"clean_text\"] = data[\"clean_text\"].astype(str)\n",
    "data[\"agreeableness\"] = data[\"agreeableness\"].astype(float)\n",
    "data[\"openness\"] = data[\"openness\"].astype(float)\n",
    "data[\"conscientiousness\"] = data[\"conscientiousness\"].astype(float)\n",
    "data[\"extraversion\"] = data[\"extraversion\"].astype(float)\n",
    "data[\"neuroticism\"] = data[\"neuroticism\"].astype(float)\n",
    "\n",
    "# Remove rows with missing values\n",
    "data = data.dropna(subset=[\"author\", \"clean_text\", \"agreeableness\", \"openness\", \"conscientiousness\", \"extraversion\", \"neuroticism\"])\n",
    "\n",
    "# # Group comments by user and calculate average personality scores\n",
    "# user_data = df[df[\"author\"].isin(valid_users)].groupby(\"author\").agg({\n",
    "#     \"clean_text\": \" \".join,\n",
    "#     \"agreeableness\": \"mean\",\n",
    "#     \"openness\": \"mean\",\n",
    "#     \"conscientiousness\": \"mean\",\n",
    "#     \"extraversion\": \"mean\",\n",
    "#     \"neuroticism\": \"mean\"\n",
    "# }).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa493431-d6db-4985-8d94-80d8b0fac75f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa493431-d6db-4985-8d94-80d8b0fac75f",
    "outputId": "d7f8effc-56a7-498e-b3c2-c4ffb6ebeb5a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_r/qsfj41cd77z4xx7f0m47czqc0000gn/T/ipykernel_19467/2840138616.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sampled_data = sampled_data.append(sampled_group, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Set the desired number of comments to be sampled per user\n",
    "comments_per_user = 100 #400\n",
    "\n",
    "# Set the minimum number of words threshold\n",
    "min_comment_length = 5\n",
    "\n",
    "# Group the data by user_id\n",
    "grouped_data = data.groupby('author')\n",
    "\n",
    "# Initialize an empty DataFrame to store the sampled data\n",
    "sampled_data = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "# Iterate over each user group\n",
    "for user_id, group in grouped_data:\n",
    "    # Filter comments based on the minimum number of words threshold\n",
    "    filtered_comments = group[group['clean_text'].apply(lambda x: len(x.split())) >= min_comment_length]\n",
    "    # Sample up to 'comments_per_user' comments\n",
    "    sampled_group = filtered_comments.sample(min(len(filtered_comments), comments_per_user))\n",
    "    # Append the sampled group to the sampled data\n",
    "    sampled_data = sampled_data.append(sampled_group, ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data to mix comments from different users\n",
    "sampled_data = sampled_data.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd8d5ea-d37c-4514-accb-262e67035aa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cd8d5ea-d37c-4514-accb-262e67035aa8",
    "outputId": "37c9f48c-415c-47f2-fd30-a34e55c692d8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124464 entries, 0 to 124463\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   author                    124464 non-null  object \n",
      " 1   body                      124464 non-null  object \n",
      " 2   word_count                124464 non-null  float64\n",
      " 3   word_count_quoteless      124464 non-null  float64\n",
      " 4   lang                      124359 non-null  object \n",
      " 5   N_exaggeration_count      124464 non-null  object \n",
      " 6   A_hedges                  124464 non-null  float64\n",
      " 7   agreeableness             124464 non-null  float64\n",
      " 8   openness                  124464 non-null  float64\n",
      " 9   conscientiousness         124464 non-null  float64\n",
      " 10  extraversion              124464 non-null  float64\n",
      " 11  neuroticism               124464 non-null  float64\n",
      " 12  agreeableness_scaled      124464 non-null  object \n",
      " 13  openness_scaled           124464 non-null  object \n",
      " 14  conscientiousness_scaled  124464 non-null  object \n",
      " 15  extraversion_scaled       124464 non-null  object \n",
      " 16  neuroticism_scaled        124464 non-null  object \n",
      " 17  clean_text                124464 non-null  object \n",
      "dtypes: float64(8), object(10)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "sampled_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f1a5bb-c853-420f-89a1-7c8f545a98a8",
   "metadata": {},
   "source": [
    "### First experiment with Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5NVDDqdzdTxN",
   "metadata": {
    "id": "5NVDDqdzdTxN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the BigFiveDataset class\n",
    "class BigFiveDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.loc[idx, 'clean_text']\n",
    "        labels = self.data.loc[idx, ['agreeableness', 'openness', 'conscientiousness', 'extraversion', 'neuroticism']].values.astype(float)\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "\n",
    "        sample = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4XLGb43kj9rM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XLGb43kj9rM",
    "outputId": "03743412-d9ea-431c-d7b3-81b91336271f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Set up the model, tokenizer, and configuration\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Dn6RE_hgj9vn",
   "metadata": {
    "id": "Dn6RE_hgj9vn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(sampled_data, test_size=0.2, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "kGcOzegrrELC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kGcOzegrrELC",
    "outputId": "aeaeba0c-c391-4ef9-d7c8-3c39ab406061",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_quoteless</th>\n",
       "      <th>lang</th>\n",
       "      <th>N_exaggeration_count</th>\n",
       "      <th>A_hedges</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness_scaled</th>\n",
       "      <th>openness_scaled</th>\n",
       "      <th>conscientiousness_scaled</th>\n",
       "      <th>extraversion_scaled</th>\n",
       "      <th>neuroticism_scaled</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fearless_Prince</td>\n",
       "      <td>I avoid mirrors like the goddamn plague becaus...</td>\n",
       "      <td>207.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>50.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>i avoid mirror like the goddamn plague because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lifeisfallingapart</td>\n",
       "      <td>You can't see much of anything.  Just BJ and a...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>you cannot see much of anything just bj and al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5il3nc3r</td>\n",
       "      <td>Pretty sure Ninja is the fastest. Swashbuckler...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>pretty sure ninja is the fastest swashbuckler ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>laidymondegreen</td>\n",
       "      <td>Maybe they do it after you show yourself out.</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>91.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>maybe they do it after you show yourself out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9Hero</td>\n",
       "      <td>A SJW in its natural habitat.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>a sjw in it natural habitat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24888</th>\n",
       "      <td>turncloak471</td>\n",
       "      <td>I agree that trying to be tactful or decisive ...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>6.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>i agree that trying to be tactful or decisive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24889</th>\n",
       "      <td>nrgstorm</td>\n",
       "      <td>The last time I was up there was shortly after...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>the last time i wa up there wa shortly after t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24890</th>\n",
       "      <td>AbstractStateMachine</td>\n",
       "      <td>Oh shit did I forget to charge the spare batte...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>oh shit did i forget to charge the spare batte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24891</th>\n",
       "      <td>d4m1t</td>\n",
       "      <td>I love your wallpaper! Link please?</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>i love your wallpaper link please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24892</th>\n",
       "      <td>lemonpielove</td>\n",
       "      <td>Hi, I have both a mawilite and a damp rock. Ca...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>hi i have both a mawilite and a damp rock can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24893 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     author  \\\n",
       "0           Fearless_Prince   \n",
       "1        Lifeisfallingapart   \n",
       "2                  5il3nc3r   \n",
       "3           laidymondegreen   \n",
       "4                     9Hero   \n",
       "...                     ...   \n",
       "24888          turncloak471   \n",
       "24889              nrgstorm   \n",
       "24890  AbstractStateMachine   \n",
       "24891                 d4m1t   \n",
       "24892          lemonpielove   \n",
       "\n",
       "                                                    body  word_count  \\\n",
       "0      I avoid mirrors like the goddamn plague becaus...       207.0   \n",
       "1      You can't see much of anything.  Just BJ and a...        14.0   \n",
       "2      Pretty sure Ninja is the fastest. Swashbuckler...        12.0   \n",
       "3          Maybe they do it after you show yourself out.         9.0   \n",
       "4                          A SJW in its natural habitat.         6.0   \n",
       "...                                                  ...         ...   \n",
       "24888  I agree that trying to be tactful or decisive ...        68.0   \n",
       "24889  The last time I was up there was shortly after...        38.0   \n",
       "24890  Oh shit did I forget to charge the spare batte...        11.0   \n",
       "24891                I love your wallpaper! Link please?         6.0   \n",
       "24892  Hi, I have both a mawilite and a damp rock. Ca...        17.0   \n",
       "\n",
       "       word_count_quoteless lang N_exaggeration_count  A_hedges  \\\n",
       "0                     161.0   en                    0  0.006211   \n",
       "1                      14.0   en                    0  0.000000   \n",
       "2                      12.0   en                    0  0.000000   \n",
       "3                       9.0   en                    0  0.111111   \n",
       "4                       6.0   en                    0  0.000000   \n",
       "...                     ...  ...                  ...       ...   \n",
       "24888                  68.0   en                    0  0.029412   \n",
       "24889                  37.0   en                    0  0.000000   \n",
       "24890                  11.0   en                    0  0.000000   \n",
       "24891                   6.0   en                    0  0.000000   \n",
       "24892                  17.0   en                    0  0.000000   \n",
       "\n",
       "       agreeableness  openness  conscientiousness  extraversion  neuroticism  \\\n",
       "0               50.0      87.0               89.0          49.0          4.0   \n",
       "1               65.0      61.0                8.0           4.0         98.0   \n",
       "2               77.0       9.0               54.0           3.0         32.0   \n",
       "3               91.0      61.0               21.0          42.0         32.0   \n",
       "4                8.0      75.0                1.0          14.0         95.0   \n",
       "...              ...       ...                ...           ...          ...   \n",
       "24888            6.0      91.0               88.0          15.0          4.0   \n",
       "24889           28.0      57.0               69.0           2.0         72.0   \n",
       "24890           80.0      92.0               25.0          84.0         78.0   \n",
       "24891           34.0      84.0                5.0          82.0         27.0   \n",
       "24892           70.0      17.0               84.0           7.0         80.0   \n",
       "\n",
       "      agreeableness_scaled openness_scaled conscientiousness_scaled  \\\n",
       "0                        3               5                        5   \n",
       "1                        4               4                        1   \n",
       "2                        4               1                        3   \n",
       "3                        5               4                        2   \n",
       "4                        1               4                        1   \n",
       "...                    ...             ...                      ...   \n",
       "24888                    1               5                        5   \n",
       "24889                    2               3                        4   \n",
       "24890                    4               5                        2   \n",
       "24891                    2               5                        1   \n",
       "24892                    4               1                        5   \n",
       "\n",
       "      extraversion_scaled neuroticism_scaled  \\\n",
       "0                       3                  1   \n",
       "1                       1                  5   \n",
       "2                       1                  2   \n",
       "3                       3                  2   \n",
       "4                       1                  5   \n",
       "...                   ...                ...   \n",
       "24888                   1                  1   \n",
       "24889                   1                  4   \n",
       "24890                   5                  4   \n",
       "24891                   5                  2   \n",
       "24892                   1                  4   \n",
       "\n",
       "                                              clean_text  \n",
       "0      i avoid mirror like the goddamn plague because...  \n",
       "1      you cannot see much of anything just bj and al...  \n",
       "2      pretty sure ninja is the fastest swashbuckler ...  \n",
       "3           maybe they do it after you show yourself out  \n",
       "4                            a sjw in it natural habitat  \n",
       "...                                                  ...  \n",
       "24888  i agree that trying to be tactful or decisive ...  \n",
       "24889  the last time i wa up there wa shortly after t...  \n",
       "24890  oh shit did i forget to charge the spare batte...  \n",
       "24891                  i love your wallpaper link please  \n",
       "24892  hi i have both a mawilite and a damp rock can ...  \n",
       "\n",
       "[24893 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "FQzV92s2j90l",
   "metadata": {
    "id": "FQzV92s2j90l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "Ib73-Wttj928",
   "metadata": {
    "id": "Ib73-Wttj928",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the custom datasets\n",
    "train_dataset = BigFiveDataset(train_data, tokenizer, max_length)\n",
    "test_dataset = BigFiveDataset(test_data, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2tSTNGThj95R",
   "metadata": {
    "id": "2tSTNGThj95R",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the data loaders\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Q0cKFZdpj99p",
   "metadata": {
    "id": "Q0cKFZdpj99p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # !pip install --upgrade accelerate\n",
    "# !pip uninstall -y transformers accelerate\n",
    "# !pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "-QCLX_epj-AB",
   "metadata": {
    "id": "-QCLX_epj-AB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/huggingface/accelerate\n",
    "# !pip install transformers==4.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "AiK8VFQJj97Z",
   "metadata": {
    "id": "AiK8VFQJj97Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "laKRsd5Dj-Cr",
   "metadata": {
    "id": "laKRsd5Dj-Cr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the regression model\n",
    "class BigFiveModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(BigFiveModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.regression = nn.Linear(config.hidden_size, 5)  # 5 traits\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.regression(pooled_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0s0dNoSWj-E2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0s0dNoSWj-E2",
    "outputId": "d8883712-f63d-4504-c711-2c06cf025cc6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desislavamarvakov/opt/anaconda3/envs/Study/lib/python3.9/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the regression model\n",
    "regression_model = BigFiveModel(model)\n",
    "\n",
    "# Define the MSE loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Create the optimizer and scheduler\n",
    "optimizer = AdamW(regression_model.parameters(), lr=1e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(train_dataloader) * training_args.num_train_epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "qylJwSCkj-HG",
   "metadata": {
    "id": "qylJwSCkj-HG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "regression_model.to(device)\n",
    "\n",
    "# Training loop\n",
    "regression_model.train()\n",
    "\n",
    "for epoch in range(training_args.num_train_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device).long()  # Convert to Long\n",
    "        attention_mask = batch['attention_mask'].to(device).float()\n",
    "        labels = batch['labels'].to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = regression_model(input_ids, attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DzGyjDjrj-Jg",
   "metadata": {
    "id": "DzGyjDjrj-Jg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation loop\n",
    "regression_model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        logits = regression_model(input_ids, attention_mask)\n",
    "        predictions.extend(logits.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "mse = mean_squared_error(true_labels, predictions)\n",
    "r2 = r2_score(true_labels, predictions)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0ad52-c19a-41bb-b8da-c68cc8fb1f70",
   "metadata": {
    "id": "jCn50fIMdUDP"
   },
   "source": [
    "#### Second experiment with Glove, SVD and Bert, Multi regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9fddd-5eeb-4d7e-a0fb-2f4f84e2a086",
   "metadata": {
    "id": "b5c9fddd-5eeb-4d7e-a0fb-2f4f84e2a086",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(sampled_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea9057-cf8b-47f9-98d1-c2f216c2aec4",
   "metadata": {
    "id": "44ea9057-cf8b-47f9-98d1-c2f216c2aec4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the percentile sequence length that covers 80% of the comment lengths\n",
    "percentile = 90  # Set the desired percentile value\n",
    "sequence_lengths = sampled_data['clean_text'].apply(lambda x: len(x.split()))\n",
    "sequence_length_threshold = np.percentile(sequence_lengths, percentile)\n",
    "\n",
    "# Determine the maximum sequence length needed to cover the specified percentile\n",
    "max_sequence_length = int(sequence_length_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81120b-d551-47a3-adf8-f66093356be8",
   "metadata": {
    "id": "ae81120b-d551-47a3-adf8-f66093356be8",
    "outputId": "fb56a087-9be6-4cf2-8c6e-d024801c8dda",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a21be7-7bc5-435e-a25f-84996a84e09c",
   "metadata": {
    "id": "38a21be7-7bc5-435e-a25f-84996a84e09c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decided to go on fixed param\n",
    "# Define constants\n",
    "max_sequence_length = 100  # Maximum sequence length for padding/truncation\n",
    "embedding_dim = 100  # Dimensionality of GLOVE word embeddings\n",
    "num_components = 50  # Number of components for SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6f35e-b9da-4ada-98b4-4b35b2dbc305",
   "metadata": {
    "id": "51d6f35e-b9da-4ada-98b4-4b35b2dbc305",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize text using GLOVE word embeddings\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52535dfe-0e68-41b1-aec2-438e3ddb688e",
   "metadata": {
    "id": "52535dfe-0e68-41b1-aec2-438e3ddb688e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert text to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data[\"clean_text\"])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c1f16-b7cf-48dd-b001-4e15eaf8d9e0",
   "metadata": {
    "id": "697c1f16-b7cf-48dd-b001-4e15eaf8d9e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pad sequences to the maximum sequence length\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_sequence_length, padding='post')\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6214ae-6e70-4742-8d53-ce61192d95ab",
   "metadata": {
    "id": "6f6214ae-6e70-4742-8d53-ce61192d95ab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load GLOVE word embeddings\n",
    "glove_embeddings = {}\n",
    "with open(\"glove.6B.100d.txt\", encoding=\"utf8\") as file:  # Replace with path to your GLOVE file\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype=\"float32\")\n",
    "        glove_embeddings[word] = embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99212ed-d64b-49a4-8323-5fea1dc5e393",
   "metadata": {
    "id": "e99212ed-d64b-49a4-8323-5fea1dc5e393",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an embedding matrix\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff866340-8378-4217-9ba9-0eb4cb376b8d",
   "metadata": {
    "id": "ff866340-8378-4217-9ba9-0eb4cb376b8d",
    "outputId": "54026ec6-f85f-48ec-ac95-bd6086185536",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       [-0.046539  ,  0.61966002,  0.56647003, ..., -0.37616   ,\n",
       "        -0.032502  ,  0.80620003],\n",
       "       ...,\n",
       "       [-0.13805   ,  0.55756003, -0.80915999, ...,  0.14061999,\n",
       "         0.33471999, -0.18887   ],\n",
       "       [ 0.0022    , -0.29567999,  0.77519   , ...,  1.12779999,\n",
       "         1.76489997,  1.07439995],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd68f3-bc5e-4158-bdba-a5b17612ba91",
   "metadata": {
    "id": "18dd68f3-bc5e-4158-bdba-a5b17612ba91",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply SVD for dimensionality reduction\n",
    "svd = TruncatedSVD(n_components=num_components, random_state=42)\n",
    "train_features = svd.fit_transform(train_sequences)\n",
    "test_features = svd.transform(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543693a-0a24-46ae-9437-8e9d28f66ead",
   "metadata": {
    "id": "9543693a-0a24-46ae-9437-8e9d28f66ead",
    "outputId": "d98092fe-0973-466e-9910-7d90606cd370",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa4351-6d57-484a-9e1a-d4836661f4b0",
   "metadata": {
    "id": "a0fa4351-6d57-484a-9e1a-d4836661f4b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define batch size and maximum sequence length per batch\n",
    "batch_size = 32\n",
    "max_batch_sequence_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49609a-267e-4e24-ad7a-9f8a45302b0a",
   "metadata": {
    "id": "3d49609a-267e-4e24-ad7a-9f8a45302b0a",
    "outputId": "64aa2e0d-e8ac-4489-d964-8b4717d6cd8b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_bert_outputs = []\n",
    "num_train_batches = int(np.ceil(len(train_data) / batch_size))\n",
    "for i in range(num_train_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(train_data))\n",
    "    train_batch = train_data.iloc[start_idx:end_idx]\n",
    "    train_encoded_batch = tokenizer.batch_encode_plus(\n",
    "        train_batch[\"clean_text\"].tolist(),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_batch_sequence_length,\n",
    "        return_tensors=\"tf\",\n",
    "        return_token_type_ids=True  # Include token_type_ids for segment differentiation\n",
    "    )\n",
    "    train_bert_inputs_batch = {\n",
    "        \"input_ids\": train_encoded_batch[\"input_ids\"],\n",
    "        \"attention_mask\": train_encoded_batch[\"attention_mask\"],\n",
    "        \"token_type_ids\": train_encoded_batch[\"token_type_ids\"]\n",
    "    }\n",
    "    train_bert_outputs_batch = bert_model(train_bert_inputs_batch)[0]\n",
    "    train_bert_outputs.append(train_bert_outputs_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aee3a6-d747-4be7-9d91-06fa544222a1",
   "metadata": {
    "id": "12aee3a6-d747-4be7-9d91-06fa544222a1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_bert_outputs = np.concatenate(train_bert_outputs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f99a6-a0c8-40cb-a766-abe662d41d00",
   "metadata": {
    "id": "902f99a6-a0c8-40cb-a766-abe662d41d00",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process test data in batches\n",
    "test_bert_outputs = []\n",
    "num_test_batches = int(np.ceil(len(test_data) / batch_size))\n",
    "for i in range(num_test_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(test_data))\n",
    "    test_batch = test_data.iloc[start_idx:end_idx]\n",
    "    test_encoded_batch = tokenizer.batch_encode_plus(\n",
    "        test_batch[\"clean_text\"].tolist(),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_batch_sequence_length,\n",
    "        return_tensors=\"tf\",\n",
    "        return_token_type_ids=True  # Include token_type_ids for segment differentiation\n",
    "    )\n",
    "    test_bert_inputs_batch = {\n",
    "        \"input_ids\": test_encoded_batch[\"input_ids\"],\n",
    "        \"attention_mask\": test_encoded_batch[\"attention_mask\"],\n",
    "        \"token_type_ids\": test_encoded_batch[\"token_type_ids\"]\n",
    "    }\n",
    "    test_bert_outputs_batch = bert_model(test_bert_inputs_batch)[0]\n",
    "    test_bert_outputs.append(test_bert_outputs_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e7e3a-a637-48ea-bea1-b96572b15ee5",
   "metadata": {
    "id": "449e7e3a-a637-48ea-bea1-b96572b15ee5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_bert_outputs = np.concatenate(test_bert_outputs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894ce2a-bb9b-4e61-83b1-fea97cd2ecb2",
   "metadata": {
    "id": "2894ce2a-bb9b-4e61-83b1-fea97cd2ecb2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get BERT embeddings\n",
    "train_bert_inputs = [train_encoded[\"input_ids\"], train_encoded[\"attention_mask\"]]\n",
    "train_bert_outputs = bert_model(train_bert_inputs)[0]\n",
    "test_bert_inputs = [test_encoded[\"input_ids\"], test_encoded[\"attention_mask\"]]\n",
    "test_bert_outputs = bert_model(test_bert_inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f2cf8-c6f6-426e-957e-95d62294e644",
   "metadata": {
    "id": "079f2cf8-c6f6-426e-957e-95d62294e644",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_glove = Input(shape=(num_components,), name=\"glove_input\")\n",
    "input_bert = Input(shape=(max_sequence_length, 768), name=\"bert_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2798a48-6500-4307-abe1-ede33e731bda",
   "metadata": {
    "id": "e2798a48-6500-4307-abe1-ede33e731bda"
   },
   "outputs": [],
   "source": [
    "# GLOVE branch\n",
    "glove_layer = Dense(128, activation=\"relu\")(input_glove)\n",
    "\n",
    "# BERT branch\n",
    "bert_lstm = LSTM(128, return_sequences=True)(input_bert)\n",
    "bert_layer = LSTM(64)(bert_lstm)\n",
    "\n",
    "# Merge branches\n",
    "merged_layer = concatenate([glove_layer, bert_layer])\n",
    "output_layer1 = Dense(1, name=\"output_openness\")(merged_layer)\n",
    "output_layer2 = Dense(1, name=\"output_conscientiousness\")(merged_layer)\n",
    "output_layer3 = Dense(1, name=\"output_extraversion\")(merged_layer)\n",
    "output_layer4 = Dense(1, name=\"output_agreeableness\")(merged_layer)\n",
    "output_layer5 = Dense(1, name=\"output_neuroticism\")(merged_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input_glove, input_bert], outputs=[output_layer1, output_layer2, output_layer3,\n",
    "                                                          output_layer4, output_layer5])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss=MeanSquaredError())\n",
    "\n",
    "# Define the checkpoint path\n",
    "checkpoint_path = \"model_checkpoints/model_checkpoint.h5\"\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True,\n",
    "                                      monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model with the checkpoint callback\n",
    "model.fit([train_features, train_bert_outputs], [train_data[\"openness\"], train_data[\"conscientiousness\"],\n",
    "                                                 train_data[\"extraversion\"], train_data[\"agreeableness\"],\n",
    "                                                 train_data[\"neuroticism\"]],\n",
    "          epochs=10, batch_size=32, validation_split=0.2, callbacks=[checkpoint_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict([test_features, test_bert_outputs])\n",
    "mse = mean_squared_error([test_data[\"openness\"], test_data[\"conscientiousness\"],\n",
    "                          test_data[\"extraversion\"], test_data[\"agreeableness\"],\n",
    "                          test_data[\"neuroticism\"]], predictions)\n",
    "print(\"MSE:\", mse)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Study)",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
